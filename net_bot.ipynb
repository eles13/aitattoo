{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile net_bot.py\n",
    "style_transfer_dir = './Real-time-multi-style-transfer/'\n",
    "import telebot\n",
    "from telebot import TeleBot\n",
    "from telebot import types\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import logging\n",
    "#from pymorphy2 import MorphAnalyzer\n",
    "import requests\n",
    "import wget\n",
    "import pickle\n",
    "import sys\n",
    "import pickle\n",
    "import argparse\n",
    "from os.path import join\n",
    "import scipy.misc\n",
    "import random\n",
    "import imageio\n",
    "import model\n",
    "if style_transfer_dir not in sys.path:\n",
    "    sys.path.append(style_transfer_dir)\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from inference.Inferencer import Inferencer\n",
    "from models.PasticheModel import PasticheModel\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import pika\n",
    "import base64\n",
    "import joblib\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from own_style import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing placeholder\n",
      "Building the Generator\n",
      "WARNING:tensorflow:From /home/pe/anaconda3/envs/pycode/lib/python3.7/site-packages/tf_slim/layers/layers.py:684: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Building the Discriminator\n",
      "Building the Loss Function\n",
      "List of all variables\n",
      "g_embedding/Matrix:0\n",
      "<tf.Variable 'g_embedding/Matrix:0' shape=(512, 256) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_embedding/Matrix:0 is illegal; using g_embedding/Matrix_0 instead.\n",
      "g_embedding/bias:0\n",
      "<tf.Variable 'g_embedding/bias:0' shape=(256,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_embedding/bias:0 is illegal; using g_embedding/bias_0 instead.\n",
      "g_h0_lin/Matrix:0\n",
      "<tf.Variable 'g_h0_lin/Matrix:0' shape=(356, 32768) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h0_lin/Matrix:0 is illegal; using g_h0_lin/Matrix_0 instead.\n",
      "g_h0_lin/bias:0\n",
      "<tf.Variable 'g_h0_lin/bias:0' shape=(32768,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h0_lin/bias:0 is illegal; using g_h0_lin/bias_0 instead.\n",
      "g_bn0/beta:0\n",
      "<tf.Variable 'g_bn0/beta:0' shape=(512,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_bn0/beta:0 is illegal; using g_bn0/beta_0 instead.\n",
      "g_h1/w:0\n",
      "<tf.Variable 'g_h1/w:0' shape=(5, 5, 256, 512) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h1/w:0 is illegal; using g_h1/w_0 instead.\n",
      "g_h1/biases:0\n",
      "<tf.Variable 'g_h1/biases:0' shape=(256,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h1/biases:0 is illegal; using g_h1/biases_0 instead.\n",
      "g_bn1/beta:0\n",
      "<tf.Variable 'g_bn1/beta:0' shape=(256,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_bn1/beta:0 is illegal; using g_bn1/beta_0 instead.\n",
      "g_h2/w:0\n",
      "<tf.Variable 'g_h2/w:0' shape=(5, 5, 128, 256) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h2/w:0 is illegal; using g_h2/w_0 instead.\n",
      "g_h2/biases:0\n",
      "<tf.Variable 'g_h2/biases:0' shape=(128,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h2/biases:0 is illegal; using g_h2/biases_0 instead.\n",
      "g_bn2/beta:0\n",
      "<tf.Variable 'g_bn2/beta:0' shape=(128,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_bn2/beta:0 is illegal; using g_bn2/beta_0 instead.\n",
      "g_h3/w:0\n",
      "<tf.Variable 'g_h3/w:0' shape=(5, 5, 64, 128) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h3/w:0 is illegal; using g_h3/w_0 instead.\n",
      "g_h3/biases:0\n",
      "<tf.Variable 'g_h3/biases:0' shape=(64,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h3/biases:0 is illegal; using g_h3/biases_0 instead.\n",
      "g_bn3/beta:0\n",
      "<tf.Variable 'g_bn3/beta:0' shape=(64,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_bn3/beta:0 is illegal; using g_bn3/beta_0 instead.\n",
      "g_h4/w:0\n",
      "<tf.Variable 'g_h4/w:0' shape=(5, 5, 3, 64) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h4/w:0 is illegal; using g_h4/w_0 instead.\n",
      "g_h4/biases:0\n",
      "<tf.Variable 'g_h4/biases:0' shape=(3,) dtype=float32>\n",
      "INFO:tensorflow:Summary name g_h4/biases:0 is illegal; using g_h4/biases_0 instead.\n",
      "d_h0_conv/w:0\n",
      "<tf.Variable 'd_h0_conv/w:0' shape=(5, 5, 3, 64) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h0_conv/w:0 is illegal; using d_h0_conv/w_0 instead.\n",
      "d_h0_conv/biases:0\n",
      "<tf.Variable 'd_h0_conv/biases:0' shape=(64,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h0_conv/biases:0 is illegal; using d_h0_conv/biases_0 instead.\n",
      "d_h1_conv/w:0\n",
      "<tf.Variable 'd_h1_conv/w:0' shape=(5, 5, 64, 128) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h1_conv/w:0 is illegal; using d_h1_conv/w_0 instead.\n",
      "d_h1_conv/biases:0\n",
      "<tf.Variable 'd_h1_conv/biases:0' shape=(128,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h1_conv/biases:0 is illegal; using d_h1_conv/biases_0 instead.\n",
      "d_bn1/beta:0\n",
      "<tf.Variable 'd_bn1/beta:0' shape=(128,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_bn1/beta:0 is illegal; using d_bn1/beta_0 instead.\n",
      "d_h2_conv/w:0\n",
      "<tf.Variable 'd_h2_conv/w:0' shape=(5, 5, 128, 256) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h2_conv/w:0 is illegal; using d_h2_conv/w_0 instead.\n",
      "d_h2_conv/biases:0\n",
      "<tf.Variable 'd_h2_conv/biases:0' shape=(256,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h2_conv/biases:0 is illegal; using d_h2_conv/biases_0 instead.\n",
      "d_bn2/beta:0\n",
      "<tf.Variable 'd_bn2/beta:0' shape=(256,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_bn2/beta:0 is illegal; using d_bn2/beta_0 instead.\n",
      "d_h3_conv/w:0\n",
      "<tf.Variable 'd_h3_conv/w:0' shape=(5, 5, 256, 512) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h3_conv/w:0 is illegal; using d_h3_conv/w_0 instead.\n",
      "d_h3_conv/biases:0\n",
      "<tf.Variable 'd_h3_conv/biases:0' shape=(512,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h3_conv/biases:0 is illegal; using d_h3_conv/biases_0 instead.\n",
      "d_bn3/beta:0\n",
      "<tf.Variable 'd_bn3/beta:0' shape=(512,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_bn3/beta:0 is illegal; using d_bn3/beta_0 instead.\n",
      "d_embedding/Matrix:0\n",
      "<tf.Variable 'd_embedding/Matrix:0' shape=(512, 256) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_embedding/Matrix:0 is illegal; using d_embedding/Matrix_0 instead.\n",
      "d_embedding/bias:0\n",
      "<tf.Variable 'd_embedding/bias:0' shape=(256,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_embedding/bias:0 is illegal; using d_embedding/bias_0 instead.\n",
      "d_h3_conv_new/w:0\n",
      "<tf.Variable 'd_h3_conv_new/w:0' shape=(1, 1, 768, 512) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h3_conv_new/w:0 is illegal; using d_h3_conv_new/w_0 instead.\n",
      "d_h3_conv_new/biases:0\n",
      "<tf.Variable 'd_h3_conv_new/biases:0' shape=(512,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h3_conv_new/biases:0 is illegal; using d_h3_conv_new/biases_0 instead.\n",
      "d_bn4/beta:0\n",
      "<tf.Variable 'd_bn4/beta:0' shape=(512,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_bn4/beta:0 is illegal; using d_bn4/beta_0 instead.\n",
      "d_h4_lin_rw/Matrix:0\n",
      "<tf.Variable 'd_h4_lin_rw/Matrix:0' shape=(32768, 1) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h4_lin_rw/Matrix:0 is illegal; using d_h4_lin_rw/Matrix_0 instead.\n",
      "d_h4_lin_rw/bias:0\n",
      "<tf.Variable 'd_h4_lin_rw/bias:0' shape=(1,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h4_lin_rw/bias:0 is illegal; using d_h4_lin_rw/bias_0 instead.\n",
      "d_h4_lin_ac/Matrix:0\n",
      "<tf.Variable 'd_h4_lin_ac/Matrix:0' shape=(32768, 312) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h4_lin_ac/Matrix:0 is illegal; using d_h4_lin_ac/Matrix_0 instead.\n",
      "d_h4_lin_ac/bias:0\n",
      "<tf.Variable 'd_h4_lin_ac/bias:0' shape=(312,) dtype=float32>\n",
      "INFO:tensorflow:Summary name d_h4_lin_ac/bias:0 is illegal; using d_h4_lin_ac/bias_0 instead.\n",
      "INFO:tensorflow:Summary name D loss-1 [Real/Fake loss for real images] is illegal; using D_loss-1__Real/Fake_loss_for_real_images_ instead.\n",
      "INFO:tensorflow:Summary name D loss-2 [Real/Fake loss for wrong images] is illegal; using D_loss-2__Real/Fake_loss_for_wrong_images_ instead.\n",
      "INFO:tensorflow:Summary name D loss-3 [Real/Fake loss for fake images] is illegal; using D_loss-3__Real/Fake_loss_for_fake_images_ instead.\n",
      "INFO:tensorflow:Summary name D loss-4 [Aux Classifier loss for real images] is illegal; using D_loss-4__Aux_Classifier_loss_for_real_images_ instead.\n",
      "INFO:tensorflow:Summary name D loss-5 [Aux Classifier loss for wrong images] is illegal; using D_loss-5__Aux_Classifier_loss_for_wrong_images_ instead.\n",
      "INFO:tensorflow:Summary name G loss-1 [Real/Fake loss for fake images] is illegal; using G_loss-1__Real/Fake_loss_for_fake_images_ instead.\n",
      "INFO:tensorflow:Summary name G loss-2 [Aux Classifier loss for fake images] is illegal; using G_loss-2__Aux_Classifier_loss_for_fake_images_ instead.\n",
      "INFO:tensorflow:Summary name Discriminator Real Image Accuracy is illegal; using Discriminator_Real_Image_Accuracy instead.\n",
      "INFO:tensorflow:Summary name Discriminator Wrong Image Accuracy is illegal; using Discriminator_Wrong_Image_Accuracy instead.\n",
      "INFO:tensorflow:Summary name Discriminator Fake Image Accuracy is illegal; using Discriminator_Fake_Image_Accuracy instead.\n",
      "INFO:tensorflow:Summary name Generated Images is illegal; using Generated_Images instead.\n",
      "WARNING:tensorflow:From /home/pe/anaconda3/envs/pycode/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/model_after_flowers_epoch_108.ckpt\n"
     ]
    }
   ],
   "source": [
    "connection = pika.BlockingConnection(pika.ConnectionParameters(heartbeat=0 ,socket_timeout=100000))\n",
    "channel = connection.channel()\n",
    "channel.queue_declare(queue='toenc')\n",
    "\n",
    "#################################################################\n",
    "#############################SETUP###############################\n",
    "#################################################################\n",
    "pic_path = './saved_pics/'\n",
    "text_rep_path = './texts/'\n",
    "own_styles_path = './own_styles/'\n",
    "own_pics_path = './own_pics/'\n",
    "\n",
    "#all_models_path = './pokemons/demo/models/'\n",
    "modes = {}\n",
    "stylesdct = joblib.load('./stylesNames.dict')\n",
    "ownstyle_transfer_dict = {}\n",
    "\n",
    "from string import punctuation\n",
    " \n",
    "def clean(text):\n",
    "    if not isinstance(text, str):\n",
    "        raise TypeError('text должен быть str')\n",
    "    return ''.join(x for x in text.lower() if x not in punctuation)\n",
    "\n",
    "#current_model_path = all_models_path + 'model_' + str(len(os.listdir(all_models_path)) - 1)\n",
    "\n",
    "os.makedirs(pic_path, exist_ok=True)\n",
    "os.makedirs(text_rep_path, exist_ok=True)\n",
    "os.makedirs(own_styles_path, exist_ok=True)\n",
    "os.makedirs(own_pics_path, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(filename=\"botlog.log\", level=logging.INFO, filemode='w')\n",
    "token = '1277130373:AAH7oKdzkHwopPmwVluIIVPFfU_rugTedRM'\n",
    "bot = TeleBot(token)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "num_styles = 33\n",
    "image_size = 512\n",
    "\n",
    "pastichemodel = PasticheModel(num_styles)\n",
    "model_save_dir = style_transfer_dir + \"checkpoints/pastichemodel_1-FINAL.pth\"\n",
    "\n",
    "pastichemodel = PasticheModel(num_styles)\n",
    "\n",
    "inference = Inferencer(pastichemodel,device,image_size)\n",
    "inference.load_model_weights(model_save_dir)\n",
    "\n",
    "logging.info('---started---')\n",
    "running = False\n",
    "\n",
    "logging.info('Started loading and setting model')\n",
    "def load_training_data(data_dir, data_set, caption_vector_length, n_classes):\n",
    "    if data_set == 'flowers':\n",
    "        flower_str_captions = pickle.load(\n",
    "            open(join(data_dir, 'flowers', 'flowers_caps.pkl'), \"rb\"))\n",
    "\n",
    "        img_classes = pickle.load(\n",
    "            open(join(data_dir, 'flowers', 'flower_tc.pkl'), \"rb\"))\n",
    "\n",
    "        flower_enc_captions = pickle.load(\n",
    "            open(join(data_dir, 'flowers', 'flower_tv.pkl'), \"rb\"))\n",
    "        # h1 = h5py.File(join(data_dir, 'flower_tc.hdf5'))\n",
    "        tr_image_ids = pickle.load(\n",
    "            open(join(data_dir, 'flowers', 'train_ids.pkl'), \"rb\"))\n",
    "        val_image_ids = pickle.load(\n",
    "            open(join(data_dir, 'flowers', 'val_ids.pkl'), \"rb\"))\n",
    "\n",
    "        # n_classes = n_classes\n",
    "        max_caps_len = caption_vector_length\n",
    "\n",
    "        tr_n_imgs = len(tr_image_ids)\n",
    "        val_n_imgs = len(val_image_ids)\n",
    "\n",
    "        return {\n",
    "            'image_list': tr_image_ids,\n",
    "            'captions': flower_enc_captions,\n",
    "            'data_length': tr_n_imgs,\n",
    "            'classes': img_classes,\n",
    "            'n_classes': n_classes,\n",
    "            'max_caps_len': max_caps_len,\n",
    "            'val_img_list': val_image_ids,\n",
    "            'val_captions': flower_enc_captions,\n",
    "            'val_data_len': val_n_imgs,\n",
    "            'str_captions': flower_str_captions,\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise Exception('This dataset has not been handeled yet. '\n",
    "                         'Contributions are welcome.')\n",
    "\n",
    "\n",
    "datasets_root_dir = 'datasets'\n",
    "\n",
    "loaded_data = load_training_data(datasets_root_dir, 'flowers', 512, 312)\n",
    "model_options = {\n",
    "    'z_dim': 100,\n",
    "    't_dim': 256,\n",
    "    'batch_size': 64,\n",
    "    'image_size': 128,\n",
    "    'gf_dim': 64,\n",
    "    'df_dim': 64,\n",
    "    'caption_vector_length': 512,\n",
    "    'n_classes': 312\n",
    "}\n",
    "\n",
    "gan = model.GAN(model_options)\n",
    "input_tensors, variables, loss, outputs, checks = gan.build_model()\n",
    "\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "tf.compat.v1.initialize_all_variables().run()\n",
    "\n",
    "saver = tf.compat.v1.train.Saver(max_to_keep=10000)\n",
    "logging.info('Trying to resume model from ' + str(tf.train.latest_checkpoint('./checkpoints/')))\n",
    "if tf.train.latest_checkpoint('./checkpoints/') is not None:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./checkpoints/'))\n",
    "    logging.info('Successfully loaded model from ')\n",
    "else:\n",
    "    logging.error('Could not load checkpoints. Please provide a valid path to'\n",
    "          ' your checkpoints directory')\n",
    "    exit()\n",
    "\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands = ['start'])\n",
    "def startBot(message):\n",
    "    global running\n",
    "    logging.info('Preparing to reply to \"start\" command ' + str(message.chat.id))\n",
    "    bot.reply_to(message,'Hi, this is an ai tattoo bot! Send me a description of your desirable picture and there will be magic')\n",
    "    logging.info('Replied to \"start\" command ' + str(message.chat.id))\n",
    "    running = True\n",
    "    return\n",
    "\n",
    "@bot.message_handler(commands = ['mode'])\n",
    "def changeMode(message):\n",
    "    if message.chat.id not in modes.keys():\n",
    "        modes[message.chat.id] = 0\n",
    "    logging.info('Received \"mode\" command ' + str(message.chat.id))\n",
    "    keyboard = types.InlineKeyboardMarkup(row_width = 1)\n",
    "    keyboard.row(types.InlineKeyboardButton(text='generate and stylize', callback_data='mode|0'))\n",
    "    keyboard.row(types.InlineKeyboardButton(text='only generate', callback_data='mode|1'))\n",
    "    keyboard.row(types.InlineKeyboardButton(text='retrieve from web and stylize', callback_data='mode|2'))\n",
    "    keyboard.row(types.InlineKeyboardButton(text='stylize my image', callback_data='mode|3'))\n",
    "    bot.send_message(message.chat.id, text = 'Choose mode', reply_markup=keyboard)\n",
    "    logging.info('Replied to \"mode\" command ' + str(message.chat.id))\n",
    "    return\n",
    "\n",
    "@bot.callback_query_handler(func=lambda call: call.data.split('|')[0] == 'mode')\n",
    "def changeItself(call):\n",
    "    if int(call.data.split('|')[1]) in [0, 1, 2, 3]:\n",
    "        modes[call.from_user.id] = int(call.data.split('|')[1]) \n",
    "        logging.info('Changed mode to ' + call.data.split('|')[1] + ' ' + str(call.from_user.id))\n",
    "        bot.send_message(call.from_user.id, 'Changed mode to ' + call.data.split('|')[1])\n",
    "    else:\n",
    "        bot.send_message(call.from_user.id, 'Invalid mode, try again')\n",
    "        logging.error('Not changed mode ' + call.data.split('|')[1] + ' ' + str(call.from_user.id))\n",
    "    return\n",
    "        \n",
    "        \n",
    "@bot.message_handler(func = lambda x : True, content_types = ['text'])\n",
    "def getText(message):\n",
    "    if message.chat.id not in modes.keys():\n",
    "        modes[message.chat.id] = 0\n",
    "    os.makedirs(pic_path + str(message.chat.id), exist_ok=True)\n",
    "    #text = ' '.join(list(map(lambda x : morph.parse(x)[0].normal_form, list(filter(lambda x: len(x) > 0, \\\n",
    "    #                                                                   str(message.text).split(' '))))))\n",
    "    text = str(message.text).lower()\n",
    "    logging.info('Received text ' + text + ' // ' + str(message.chat.id))\n",
    "#    text = clean(text)\n",
    "    opath = ''\n",
    "    tpath = ''\n",
    "    try:\n",
    "        if modes[message.chat.id] in [0,1]:\n",
    "            tpath = text_rep_path + text.replace(' ','_') + '.npy'\n",
    "            if not os.path.exists(tpath):\n",
    "                channel.basic_publish(exchange='', routing_key='toenc', body = str(text))\n",
    "                while not os.path.exists(tpath):\n",
    "                    continue\n",
    "            logging.info('Found file ' + tpath)\n",
    "            opath = pic_path + str(message.chat.id) + '/' + text.replace(' ', '_') + '.png'\n",
    "            captions = np.zeros((64,512))\n",
    "            logging.info('Loaded text repr file ' + tpath)\n",
    "            captions[63, :] = np.load(tpath, allow_pickle = False)\n",
    "            logging.info('Encoding made ' + str(message.chat.id))\n",
    "            z_noise = np.random.uniform(-1, 1, [64, 100])\n",
    "            val_feed = {\n",
    "                input_tensors['t_real_caption'].name: captions,\n",
    "                input_tensors['t_z'].name: z_noise,\n",
    "                input_tensors['t_training'].name: True\n",
    "            }\n",
    "            logging.info('Started generating ' + str(message.chat.id))\n",
    "            val_gen = sess.run(\n",
    "                [outputs['generator']],\n",
    "                feed_dict=val_feed)\n",
    "            val_gen = np.squeeze(val_gen)\n",
    "            fake_image_255 = val_gen[-1]\n",
    "            imageio.imwrite(opath,fake_image_255)\n",
    "            logging.info('Saved a pic to ' + opath)\n",
    "        elif modes[message.chat.id] == 2:\n",
    "            text = clean(text).replace(' ', '+')\n",
    "            opath = ''\n",
    "            resp = requests.get('https://go.mail.ru/search_images?fr=main&frm=main&q=' + text + '&fm=1').text\n",
    "            resp = resp.split('\"orig_url\":\"')\n",
    "            resp_ind = np.random.randint(1,len(resp) - 1)\n",
    "            resp = resp[resp_ind].split('\"')[0]\n",
    "            opath = pic_path + str(message.chat.id) + '/' + text.replace(' ','_') + '.png'\n",
    "            wget.download(resp.strip(), out = opath, bar = None)\n",
    "            logging.info('Saved a pic to ' + opath)\n",
    "    except Exception as e:\n",
    "        logging.error('Failed to get image // ' + str(message.chat.id) + ' // ' + str(e))\n",
    "        bot.send_message(message.chat.id, 'Ooops, we cannot deliver you a picture, try again later please')\n",
    "        bot.register_next_step_handler(message, getText)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    if modes[message.chat.id] in [0,2]:\n",
    "        stylizationInit(message, opath)\n",
    "        return\n",
    "    try:\n",
    "        bot.send_photo(message.chat.id, photo = open(opath, 'rb'))\n",
    "    except Exception as e:\n",
    "        logging.error('Failed to send image // ' + str(message.chat.id) + ' // ' + str(e))\n",
    "        bot.send_message(message.chat.id, 'Ooops, we cannot deliver you a picture, try again later please')\n",
    "        bot.register_next_step_handler(message, getText)\n",
    "        return\n",
    "    logging.info('Sent image to //' + str(message.chat.id))\n",
    "    return\n",
    "\n",
    "def stylizationInit(message, opath):\n",
    "    logging.info('Starting stylization //' + str(message.chat.id))\n",
    "    keyboard = types.InlineKeyboardMarkup(row_width = 1)\n",
    "    keyboard.row(types.InlineKeyboardButton(text='Choose style', callback_data='selection|0|' + opath))\n",
    "    keyboard.row(types.InlineKeyboardButton(text='Upload style image', callback_data='selection|1|' + opath))\n",
    "    bot.send_message(message.chat.id, text = 'Select stylization type', reply_markup = keyboard)\n",
    "    logging.info('Sent style type choosing to ' + str(message.chat.id))\n",
    "    return\n",
    "\n",
    "@bot.callback_query_handler(func = lambda call: call.data.split('|')[0] == 'selection')\n",
    "def styleTypeSelection(call):\n",
    "    opath = call.data.split('|')[2]\n",
    "    if call.data.split('|')[1] == '0':\n",
    "        keyboard = types.InlineKeyboardMarkup(row_width = 1)\n",
    "        for i,key in enumerate(stylesdct.keys()):\n",
    "            keyboard.row(types.InlineKeyboardButton(text=str(key), callback_data='style|' + str(i) + '|' + opath))\n",
    "        bot.send_message(call.message.chat.id, text = 'Choose style', reply_markup=keyboard)\n",
    "        logging.info('Sent style keyboard to ' + str(call.message.chat.id))\n",
    "    else:\n",
    "        bot.send_message(call.message.chat.id, 'Send me a style picture')\n",
    "        bot.register_next_step_handler(call.message, ownStyleInference)\n",
    "        ownstyle_transfer_dict[call.message.chat.id] = opath\n",
    "        logging.info('Send style image request to ' + str(call.message.chat.id))\n",
    "    return\n",
    "\n",
    "def ownStyleInference(message):\n",
    "    opath = ownstyle_transfer_dict[message.chat.id]\n",
    "    file_id = message.photo[-1].file_id\n",
    "    with open(own_styles_path + str(file_id) +  '.jpg', 'wb') as imout:\n",
    "        imout.write(bot.download_file(bot.get_file(file_id).file_path))\n",
    "    logging.info('Saved style img ' + str(file_id))\n",
    "    style_img = image_loader(own_styles_path + str(file_id) +  '.jpg')\n",
    "    content_img = image_loader(opath)\n",
    "    output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,\n",
    "                            content_img, style_img, content_img.clone())\n",
    "    output = output.squeeze(0)      \n",
    "    output = unloader(output)\n",
    "    output.save(opath)\n",
    "    try:\n",
    "        bot.send_photo(message.chat.id, photo = open(opath, 'rb'))\n",
    "    except Exception as e:\n",
    "        logging.error('Failed to send image // ' + str(message.chat.id) + ' // ' + str(e))\n",
    "        bot.send_message(message.chat.id, 'Ooops, we cannot deliver you a picture, try again later please')\n",
    "        bot.register_next_step_handler(message, getText)\n",
    "        return\n",
    "    logging.info('Sent image to //' + str(message.chat.id))\n",
    "    return\n",
    "\n",
    "@bot.message_handler(func = lambda x : True, content_types = ['photo'])\n",
    "def ownPicStylization(message):\n",
    "    if modes[message.chat.id] != 3:\n",
    "        bot.send_message(message.chat.id, 'Send text description or choose another mode')\n",
    "        return\n",
    "    opath = own_pics_path + str(len(os.listdir(own_pics_path))) + '.png'\n",
    "    file_id = message.photo[-1].file_id\n",
    "    with open(opath, 'wb') as imout:\n",
    "        imout.write(bot.download_file(bot.get_file(file_id).file_path))\n",
    "    logging.info('Saved content img ' + opath)\n",
    "    stylizationInit(message, opath)\n",
    "    return\n",
    "\n",
    "        \n",
    "@bot.callback_query_handler(func = lambda call: call.data.split('|')[0] == 'style')\n",
    "def styleCallback(call):\n",
    "    _, ind, opath = call.data.split('|')\n",
    "    sind = np.random.randint(0,len(stylesdct))\n",
    "    while sind == int(ind):\n",
    "        sind = np.random.randint(0,len(stylesdct))\n",
    "    try:\n",
    "        im = Image.open(opath).convert('RGB')\n",
    "        infer = inference.eval_image(im, int(ind), sind, 0.8)\n",
    "        infer.save(opath)\n",
    "    except Exception as e:\n",
    "        logging.error('Failed to stylize image // ' + str(call.message.chat.id) + ' // ' + str(e))\n",
    "        bot.send_message(call.message.chat.id, 'Ooops, we cannot deliver you a picture, try again later please')\n",
    "        bot.register_next_step_handler(call.message, getText)\n",
    "        return\n",
    "        \n",
    "        logging.info('Finished stylization //' + str(message.chat.id))\n",
    "        \n",
    "    try:\n",
    "        bot.send_photo(call.message.chat.id, photo = open(opath, 'rb'))\n",
    "    except Exception as e:\n",
    "        logging.error('Failed to send image // ' + str(call.message.chat.id) + ' // ' + str(e))\n",
    "        bot.send_message(call.message.chat.id, 'Ooops, we cannot deliver you a picture, try again later please')\n",
    "        bot.register_next_step_handler(call.message, getText)\n",
    "        return\n",
    "    logging.info('Sent image to //' + str(call.message.chat.id))\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################ADDITIONAL############################################\n",
    "    \n",
    "@bot.message_handler(commands = ['notify'])\n",
    "def broadcast(message):\n",
    "    \n",
    "    logging.info('Broadcast received')\n",
    "    \n",
    "    if message.from_user.username != 'eles13':\n",
    "        return\n",
    "    try:\n",
    "        bot.send_message(message.chat.id, 'Ready for input')\n",
    "        bot.register_next_step_handler(message, broadcasting_itself)\n",
    "    except Exception as e:\n",
    "        logging.error('Broadcasting start failed // ' + str(e))\n",
    "\n",
    "def broadcasting_itself(message):\n",
    "    logging.info('Broadcast starting')\n",
    "    for idd in os.listdir(pic_path):\n",
    "        try:\n",
    "            bot.send_message(int(idd), message.text)\n",
    "        except Exception as e:\n",
    "            logging.error('Failed to deliver to ' + idd)\n",
    "            bot.send_message(message.chat.id, 'Failed to deliver to ' + idd)\n",
    "            continue\n",
    "    logging.info('Broadcast finished')\n",
    "    \n",
    "@bot.message_handler(commands = ['change'])\n",
    "def change_model_init(message):\n",
    "    logging.info('Change model request received')\n",
    "    bot.send_message(message.chat.id, 'Ready for input, send a shared Google Drive link')\n",
    "    logging.info('Replied to \"change model\" request')\n",
    "    try:\n",
    "        os.mkdir(all_models_path + 'model_' + str(len(os.listdir(all_models_path))))\n",
    "        logging.info('Created directory for a new model')\n",
    "    except:\n",
    "        logging.error('Failed to create a directory for a new model')\n",
    "        bot.send_message(message.chat.id, 'Try again, failed to create a directory for a new model')\n",
    "        return\n",
    "    bot.register_next_step_handler(message, download_and_change)\n",
    "    return\n",
    "\n",
    "def download_and_change(message):\n",
    "    global gan\n",
    "    link = str(message.text).split('/')[5]\n",
    "    logging.info('Received model link ' + link)\n",
    "    current_model_path = all_models_path + 'model_' + str(len(os.listdir(all_models_path)) - 1)\n",
    "    logging.info('Starting downloading')\n",
    "    bot.send_message(message.chat.id, 'Starting downloading')\n",
    "    try:\n",
    "        gdd.download_file_from_google_drive(file_id=link,\n",
    "                                        dest_path=current_model_path + '/archive.zip',\n",
    "                                        unzip=True)\n",
    "    except Exception as e:\n",
    "        bot.send_message(message.chat.id, 'Failed to download, send link again, exception ' + str(e))\n",
    "        bot.register_next_step_handler(download_and_change)\n",
    "        logging.error('Failed to download, exception ' + str(e))\n",
    "        return\n",
    "    logging.info('Finished downloading')\n",
    "    gan = DCGan()\n",
    "    gan.load_model(current_model_path)\n",
    "    logging.info('Model changed')\n",
    "    bot.send_message(message.chat.id, 'Successfully changed model to iteration ' + str(len(os.listdir(all_models_path)) - 1))\n",
    "    return\n",
    "    \n",
    "\n",
    "bot.polling(none_stop=True, interval = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
